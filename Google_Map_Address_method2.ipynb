{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import usaddress\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36\"\n",
    "headers = {\"user-agent\" : USER_AGENT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to parse address from webpage\n",
    "def url_postal_adddress(url):\n",
    "#     USER_AGENT = \"Mozilla/5.0 (Linux; <Android Version>; <Build Tag etc.>) AppleWebKit/<WebKit Rev>(KHTML, like Gecko) Chrome/<Chrome Rev> Safari/<WebKit Rev>\"\n",
    "    USER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36\"\n",
    "    headers = {\"user-agent\" : USER_AGENT}\n",
    "    \n",
    "    RE_address=re.compile(r\"\"\"(\n",
    "                \\d{1,5}[ ]    #street number\n",
    "                (?:E\\.[ ]|S\\.[ ]|W\\.[ ]|N\\.[ ])?    #east south west north prefix\n",
    "                [a-zA-Z0-9 ]{1,20}    #street name\n",
    "                (?:street|st|avenue|ave|road|rd|highway|hwy|square|sq|trail|trl|drive|dr|court|ct|park|parkway|pkwy|circle|cir|boulevard|blvd|walk)\\W?(?=\\s)\\s*    #street surffix\n",
    "                (?:\\w{10})?\n",
    "                [a-zA-Z\\']{1,14}(?:\\s[a-zA-Z\\']{1,14}){0,1} #city\n",
    "                (?:,\\s|\\b)?(?:AL|AK|AR|AZ|CA|CO|CT|DC|DE|FL|GA|HI|IA|ID|IL|IN|KS|KY|LA|MA|MD|ME|MI|MN|MO|MS|MT|NC|ND|NE|NH|NJ|NM|NV|NY|OH|OK|OR|PA|RI|SC|SD|TN|TX|UT|VA|VT|WA|WI|WV|WY) #state\n",
    "                (?:,\\s|\\s)?\\b\\d{5}(?:[-\\s]\\d{4})?\\b    #zipcode\n",
    "                 )\"\"\", re.IGNORECASE | re.VERBOSE)\n",
    "    \n",
    "    address_parsed_list=pd.DataFrame(columns=('AddressRaw',\n",
    "    'AddressNumberPrefix',\n",
    "    'AddressNumber',\n",
    "    'AddressNumberSuffix',\n",
    "    'StreetNamePreModifier',\n",
    "    'StreetNamePreDirectional',\n",
    "    'StreetNamePreType',\n",
    "    'StreetName',\n",
    "    'StreetNamePostType',\n",
    "    'StreetNamePostDirectional',\n",
    "    'SubaddressType',\n",
    "    'SubaddressIdentifier',\n",
    "    'BuildingName',\n",
    "    'OccupancyType',\n",
    "    'OccupancyIdentifier',\n",
    "    'CornerOf',\n",
    "    'LandmarkName',\n",
    "    'PlaceName',\n",
    "    'StateName',\n",
    "    'ZipCode',\n",
    "    'USPSBoxType',\n",
    "    'USPSBoxID',\n",
    "    'USPSBoxGroupType',\n",
    "    'USPSBoxGroupID',\n",
    "    'IntersectionSeparator',\n",
    "    'Recipient'))\n",
    "    \n",
    "    resp = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "    address_list=re.findall(RE_address,soup.prettify())\n",
    "    address_list=list(set(address_list))\n",
    "    for address in address_list:\n",
    "        address_parsed=np.flip(usaddress.parse(address),1).T\n",
    "        address_df = pd.DataFrame(data=address_parsed,columns=address_parsed[0,:])\n",
    "        address_df = address_df[1:]\n",
    "        address_df['AddressRaw']=address\n",
    "        address_df = address_df.groupby(address_df.columns, axis=1).apply(lambda x: x.apply(lambda y: ' '.join([l for l in y if l is not None]), axis=1))\n",
    "        address_parsed_list=address_parsed_list.append(address_df)\n",
    "    return address_parsed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "university_list=pd.read_csv(\"universities.csv\",encoding='latin1')['University_Name']\n",
    "keyword_list=['dormitory','dormitory address', 'residence hall', 'residential hall', 'residence hall address', 'residential hall address','graduate student address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each university and each keyword, search and parse the address from google map result page\n",
    "university_address_all = pd.DataFrame()\n",
    "URL_address_missed = pd.DataFrame()\n",
    "i=0\n",
    "for keyword in keyword_list:\n",
    "    for university in university_list:\n",
    "        try:\n",
    "            search_word='+'.join((university+'+'+keyword).split())\n",
    "            URL = f\"https://www.google.com/maps/search/{search_word}\".format(search_word=search_word)\n",
    "            address_df=url_postal_adddress(URL)\n",
    "            google_map_driver_df=pd.DataFrame(columns=('University','Keyword','join_key'))\n",
    "            google_map_driver_df=google_map_driver_df.append(pd.Series([university,keyword,1], index=['University','Keyword','join_key']),ignore_index=True)\n",
    "            address_df['join_key']=1\n",
    "            google_map_address_df=pd.merge(google_map_driver_df,address_df).drop(columns=['join_key'])\n",
    "            if google_map_address_df.size>0:\n",
    "                if university_address_all.size > 0:\n",
    "                    university_address_all=university_address_all.append(google_map_address_df)\n",
    "                else:\n",
    "                    university_address_all=google_map_address_df\n",
    "                university_address_all.to_csv('university_address.csv')\n",
    "                print( i ,university ,'|', keyword ,'|', google_map_address_df.index.size-1)\n",
    "            else:\n",
    "                if URL_address_missed.size>0:\n",
    "                    URL_address_missed=URL_address_missed.append(google_map_driver_df)\n",
    "                else:\n",
    "                    URL_address_missed=google_map_driver_df\n",
    "                URL_address_missed.to_csv('university_address_missed.csv')\n",
    "                \n",
    "                print(i ,'|', university ,'|', keyword ,'|', 'no record')\n",
    "            i=i+1\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            if URL_address_missed.size>0:\n",
    "                URL_address_missed=URL_address_missed.append(google_map_driver_df)\n",
    "            else:\n",
    "                URL_address_missed=google_map_driver_df\n",
    "            URL_address_missed.to_csv('university_address_missed.csv')\n",
    "            time.sleep(2)\n",
    "            print('error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
